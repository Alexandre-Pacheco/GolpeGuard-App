{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "colab": {
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install flask pyngrok openai google-generativeai scikit-learn joblib APScheduler requests beautifulsoup4 python-dotenv --quiet"
      ],
      "metadata": {
        "id": "f7ooBmC9FMvp"
      },
      "id": "f7ooBmC9FMvp",
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "readme_content = \"\"\"\n",
        "# ... (cole o conteúdo do README.md aqui) ...\n",
        "\"\"\"\n",
        "with open(\"README.md\", \"w\", encoding=\"utf-8\") as f:\n",
        "    f.write(readme_content)\n",
        "print(\"Arquivo README.md salvo.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YI4iWc_RRWv2",
        "outputId": "680a6ba8-afb6-4a09-8374-d0a78cd6fd5f"
      },
      "id": "YI4iWc_RRWv2",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Arquivo README.md salvo.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "requirements_content = \"\"\"\n",
        "# ... (cole o conteúdo do requirements.txt aqui) ...\n",
        "\"\"\"\n",
        "with open(\"requirements.txt\", \"w\", encoding=\"utf-8\") as f:\n",
        "    f.write(requirements_content)\n",
        "print(\"Arquivo requirements.txt salvo.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DyMKgr1QRXkr",
        "outputId": "26cdabbc-1c61-4fca-ad63-6aebcb9c93d4"
      },
      "id": "DyMKgr1QRXkr",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Arquivo requirements.txt salvo.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install flask pyngrok openai scikit-learn joblib APScheduler requests beautifulsoup4 python-dotenv --quiet"
      ],
      "metadata": {
        "id": "xt_LFKDipD81"
      },
      "id": "xt_LFKDipD81",
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install flask pyngrok openai google-generativeai scikit-learn joblib APScheduler requests beautifulsoup4 python-dotenv numpy --quiet"
      ],
      "metadata": {
        "id": "_2tgcvhuG5kA"
      },
      "id": "_2tgcvhuG5kA",
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "if not os.path.exists(\"templates\"):\n",
        "    os.makedirs(\"templates\")\n",
        "\n",
        "app_py_content = \"\"\"\n",
        "# Imports necessários\n",
        "from flask import Flask, request, render_template, jsonify\n",
        "# ... COLE TODO O CÓDIGO PYTHON ATUALIZADO AQUI ...\n",
        "default_port = int(os.getenv(\"PORT\", 5005))\n",
        "try_run_app_with_ngrok(initial_port=default_port)\n",
        "\"\"\"\n",
        "with open(\"app.py\", \"w\", encoding=\"utf-8\") as f:\n",
        "    f.write(app_py_content)\n",
        "print(\"Arquivo app.py salvo com a correção do ngrok.connect().\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NNifQhRzpEt5",
        "outputId": "e87c2241-f35e-43bd-e70f-579d82b8fff0"
      },
      "id": "NNifQhRzpEt5",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Arquivo app.py salvo com a correção do ngrok.connect().\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python app.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iWEENgpMpHmB",
        "outputId": "8568b140-e342-4924-9e4c-51c5d5090538"
      },
      "id": "iWEENgpMpHmB",
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/content/app.py\", line 5, in <module>\n",
            "    default_port = int(os.getenv(\"PORT\", 5005))\n",
            "                       ^^\n",
            "NameError: name 'os' is not defined\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "if not os.path.exists(\"templates\"):\n",
        "    os.makedirs(\"templates\")\n",
        "\n",
        "app_py_content = \"\"\"\n",
        "# Imports necessários\n",
        "from flask import Flask, request, render_template, jsonify\n",
        "# ... COLE TODO O CÓDIGO PYTHON ATUALIZADO AQUI ...\n",
        "default_port = int(os.getenv(\"PORT\", 5005))\n",
        "try_run_app_with_ngrok(initial_port=default_port)\n",
        "\"\"\"\n",
        "with open(\"app.py\", \"w\", encoding=\"utf-8\") as f:\n",
        "    f.write(app_py_content)\n",
        "print(\"Arquivo app.py salvo com lógica Multi-IA.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bFKlmCZgFOzp",
        "outputId": "ba90653a-a23e-4798-b9e8-88ad68e41813"
      },
      "id": "bFKlmCZgFOzp",
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Arquivo app.py salvo com lógica Multi-IA.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Imports necessários\n",
        "from flask import Flask, request, render_template, jsonify\n",
        "import openai # Para ChatGPT\n",
        "import google.generativeai as genai # Para Gemini\n",
        "import json\n",
        "import os\n",
        "import hashlib\n",
        "import logging\n",
        "import joblib\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
        "import numpy as np # Para cálculos numéricos, especialmente com scikit-learn\n",
        "from threading import Thread\n",
        "from apscheduler.schedulers.background import BackgroundScheduler\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import time\n",
        "from dotenv import load_dotenv\n",
        "import socket\n",
        "from pyngrok import ngrok, conf\n",
        "from functools import wraps # Para o decorador de autenticação\n",
        "\n",
        "# Carregar variáveis de ambiente do arquivo .env\n",
        "load_dotenv()\n",
        "\n",
        "# Inicialização do Flask app\n",
        "app = Flask(__name__)\n",
        "\n",
        "# --- Configuração das Chaves de API e Outras Configurações ---\n",
        "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
        "GEMINI_API_KEY = os.getenv(\"GEMINI_API_KEY\")\n",
        "RETRAIN_API_KEY_SECRET = os.getenv(\"RETRAIN_API_KEY\") # Chave para proteger o endpoint de retreinamento\n",
        "\n",
        "# Configuração do cliente OpenAI\n",
        "if OPENAI_API_KEY:\n",
        "    if OPENAI_API_KEY.startswith(\"sk-\"):\n",
        "        openai.api_key = OPENAI_API_KEY\n",
        "        logging.info(\"Chave da API OpenAI carregada e parece válida.\")\n",
        "    else:\n",
        "        logging.error(\"Chave da API OpenAI (OPENAI_API_KEY) fornecida não parece ser válida (não começa com 'sk-'). Funcionalidade do ChatGPT desabilitada.\")\n",
        "        OPENAI_API_KEY = None # Desabilita se a chave for inválida\n",
        "else:\n",
        "    logging.warning(\"Chave da API OpenAI (OPENAI_API_KEY) não encontrada. Funcionalidade do ChatGPT desabilitada.\")\n",
        "\n",
        "# Configuração do cliente Gemini\n",
        "if GEMINI_API_KEY:\n",
        "    try:\n",
        "        # Chaves Gemini podem começar com 'AIza...'\n",
        "        genai.configure(api_key=GEMINI_API_KEY)\n",
        "        logging.info(\"Chave da API Gemini configurada com sucesso.\")\n",
        "    except Exception as e:\n",
        "        logging.error(f\"Erro ao configurar a API Gemini: {e}. Funcionalidade do Gemini desabilitada.\")\n",
        "        GEMINI_API_KEY = None\n",
        "else:\n",
        "    logging.warning(\"Chave da API Gemini (GEMINI_API_KEY) não encontrada. Funcionalidade do Gemini desabilitada.\")\n",
        "\n",
        "# Configuração do logging\n",
        "logging.basicConfig(\n",
        "    filename=\"log_app.log\",\n",
        "    level=logging.INFO,\n",
        "    format='%(asctime)s - %(levelname)s - %(module)s - %(funcName)s - %(message)s'\n",
        ")\n",
        "console_handler = logging.StreamHandler()\n",
        "console_handler.setLevel(logging.INFO) # Mostra logs INFO e acima no console\n",
        "formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')\n",
        "console_handler.setFormatter(formatter)\n",
        "# Evita adicionar handlers duplicados se a célula/script for executado múltiplas vezes\n",
        "logger = logging.getLogger()\n",
        "if not any(isinstance(h, logging.StreamHandler) for h in logger.handlers):\n",
        "    logger.addHandler(console_handler)\n",
        "logger.setLevel(logging.INFO) # Garante que o logger raiz também tem o nível INFO\n",
        "\n",
        "\n",
        "# Constantes para nomes de arquivos e configurações\n",
        "EXEMPLOS_GOLPES_FILE = \"exemplos_golpes.json\"\n",
        "MODELO_PKL_FILE = \"modelo_golpe_guard.pkl\"\n",
        "MODEL_EVALUATION_FILE = \"model_evaluation_report.txt\"\n",
        "MODELO_LOCAL_CONFIANCA_LIMIAR = 0.70 # Limiar de confiança para o modelo local\n",
        "API_RETRY_ATTEMPTS = 2 # Número de tentativas para chamadas de API externas\n",
        "API_RETRY_DELAY = 3 # Delay em segundos entre tentativas\n",
        "\n",
        "# ---------- Decorador de Autenticação para Rotas Protegidas ------------\n",
        "def require_api_key(f):\n",
        "    @wraps(f)\n",
        "    def decorated_function(*args, **kwargs):\n",
        "        if not RETRAIN_API_KEY_SECRET:\n",
        "            logging.error(\"Chave RETRAIN_API_KEY não configurada no servidor. Endpoint desabilitado.\")\n",
        "            return jsonify({\"erro\": \"Endpoint de retreinamento não configurado corretamente no servidor.\"}), 500\n",
        "\n",
        "        provided_token = request.headers.get('X-Retrain-Token')\n",
        "        if provided_token and provided_token == RETRAIN_API_KEY_SECRET:\n",
        "            return f(*args, **kwargs)\n",
        "        else:\n",
        "            logging.warning(\"Tentativa de acesso não autorizado ao endpoint de retreinamento.\")\n",
        "            return jsonify({\"erro\": \"Não autorizado. Token de retreinamento inválido ou não fornecido.\"}), 401\n",
        "    return decorated_function\n",
        "\n",
        "# ---------- Funções base para manipular a base de dados local ------------\n",
        "def carregar_base():\n",
        "    try:\n",
        "        with open(EXEMPLOS_GOLPES_FILE, \"r\", encoding=\"utf-8\") as f:\n",
        "            return json.load(f)\n",
        "    except FileNotFoundError:\n",
        "        return []\n",
        "    except json.JSONDecodeError:\n",
        "        logging.error(f\"Erro ao decodificar JSON do arquivo {EXEMPLOS_GOLPES_FILE}.\")\n",
        "        return []\n",
        "\n",
        "def salvar_base(dados):\n",
        "    try:\n",
        "        with open(EXEMPLOS_GOLPES_FILE, \"w\", encoding=\"utf-8\") as f:\n",
        "            json.dump(dados, f, indent=4, ensure_ascii=False)\n",
        "    except IOError as e:\n",
        "        logging.error(f\"Erro de I/O ao salvar {EXEMPLOS_GOLPES_FILE}: {e}\")\n",
        "\n",
        "def adicionar_nova_entrada(base_dados, mensagem, classificacao):\n",
        "    # Normaliza a classificação para garantir consistência\n",
        "    classificacao_lower = str(classificacao).lower() # Garante que é string antes de lower()\n",
        "    if \"não é golpe\" in classificacao_lower:\n",
        "        classificacao_normalizada = \"Não é golpe\"\n",
        "    elif \"golpe\" in classificacao_lower:\n",
        "        classificacao_normalizada = \"Golpe\"\n",
        "    else:\n",
        "        logging.warning(f\"Classificação '{classificacao}' não reconhecida para adicionar à base. Mensagem: {mensagem[:50]}...\")\n",
        "        return base_dados\n",
        "\n",
        "    hash_msg_nova = hashlib.sha256(mensagem.encode(\"utf-8\")).hexdigest()\n",
        "    mensagem_encontrada = False\n",
        "    for entrada in base_dados:\n",
        "        hash_msg_existente = hashlib.sha256(entrada[\"mensagem\"].encode(\"utf-8\")).hexdigest()\n",
        "        if hash_msg_existente == hash_msg_nova:\n",
        "            if entrada[\"classificacao\"] != classificacao_normalizada:\n",
        "                logging.info(f\"Atualizando classificação da mensagem (hash: {hash_msg_nova[:7]}...) de '{entrada['classificacao']}' para '{classificacao_normalizada}'.\")\n",
        "                entrada[\"classificacao\"] = classificacao_normalizada\n",
        "            else: # Adicionado log para quando a classificação é a mesma\n",
        "                 logging.info(f\"Mensagem (hash: {hash_msg_nova[:7]}...) já existe com a mesma classificação '{classificacao_normalizada}'. Nenhuma alteração na base.\")\n",
        "            mensagem_encontrada = True\n",
        "            break\n",
        "    if not mensagem_encontrada:\n",
        "        base_dados.append({\"mensagem\": mensagem, \"classificacao\": classificacao_normalizada})\n",
        "        logging.info(f\"Nova entrada adicionada à base (hash: {hash_msg_nova[:7]}...): {classificacao_normalizada}\")\n",
        "    return base_dados\n",
        "\n",
        "# ---------- Treinamento, Avaliação e Carregamento do Modelo Local ------------\n",
        "def avaliar_modelo(modelo, X_test, y_test):\n",
        "    if not hasattr(modelo, \"predict\"):\n",
        "        logging.warning(\"Tentativa de avaliar um modelo inválido ou não treinado.\")\n",
        "        return \"Modelo inválido ou não treinado para avaliação.\"\n",
        "    try:\n",
        "        y_pred = modelo.predict(X_test)\n",
        "        labels = sorted(list(set(y_test) | set(y_pred)))\n",
        "        if not labels: labels = None\n",
        "\n",
        "        report = classification_report(y_test, y_pred, zero_division=0, labels=labels)\n",
        "        cm = confusion_matrix(y_test, y_pred, labels=labels)\n",
        "        accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "        evaluation_text = f\"Relatório de Avaliação do Modelo Local ({time.strftime('%Y-%m-%d %H:%M:%S')}):\\n\"\n",
        "        evaluation_text += f\"Acurácia: {accuracy:.4f}\\n\"\n",
        "        evaluation_text += \"Relatório de Classificação:\\n\"\n",
        "        evaluation_text += report + \"\\n\"\n",
        "        evaluation_text += \"Matriz de Confusão:\\n\"\n",
        "        evaluation_text += str(cm) + \"\\n\"\n",
        "        evaluation_text += \"------------------------------------------------------\\n\"\n",
        "\n",
        "        logging.info(f\"Avaliação do modelo local: Acurácia={accuracy:.4f}\")\n",
        "        with open(MODEL_EVALUATION_FILE, \"a\", encoding=\"utf-8\") as f:\n",
        "            f.write(evaluation_text)\n",
        "        return evaluation_text\n",
        "    except Exception as e:\n",
        "        logging.error(f\"Erro durante a avaliação do modelo: {e}\")\n",
        "        return f\"Erro durante a avaliação do modelo: {e}\"\n",
        "\n",
        "def treinar_modelo():\n",
        "    dados = carregar_base()\n",
        "    if not dados:\n",
        "        logging.warning(\"Base de dados vazia. Pulando treinamento.\")\n",
        "        return None\n",
        "\n",
        "    mensagens = [d[\"mensagem\"] for d in dados if isinstance(d.get(\"mensagem\"), str) and d.get(\"mensagem\") and d.get(\"classificacao\") in [\"Golpe\", \"Não é golpe\"]]\n",
        "    etiquetas = [d[\"classificacao\"] for d in dados if isinstance(d.get(\"mensagem\"), str) and d.get(\"mensagem\") and d.get(\"classificacao\") in [\"Golpe\", \"Não é golpe\"]]\n",
        "\n",
        "    if len(mensagens) < 5 or len(set(etiquetas)) < 2:\n",
        "        logging.warning(f\"Dados insuficientes para treinamento (mensagens válidas: {len(mensagens)}, classes distintas: {len(set(etiquetas))}). Pulando.\")\n",
        "        return None\n",
        "\n",
        "    modelo = make_pipeline(TfidfVectorizer(), MultinomialNB())\n",
        "\n",
        "    try:\n",
        "        if len(set(etiquetas)) > 1 and len(mensagens) > 1 :\n",
        "            min_samples_per_class = min(np.unique(etiquetas, return_counts=True)[1]) if etiquetas else 0\n",
        "            test_size = 0.2\n",
        "            # Ajusta test_size ou desabilita stratify se houver poucas amostras\n",
        "            can_stratify = min_samples_per_class >= 2\n",
        "            actual_test_size = test_size if len(mensagens) * test_size >= 1 else 0.1 # Garante pelo menos 1 no teste se possível\n",
        "            if len(mensagens) * actual_test_size < 1 : # Se ainda não for possível ter amostra de teste\n",
        "                X_train, X_test, y_train, y_test = mensagens, [], etiquetas, []\n",
        "            elif can_stratify:\n",
        "                 X_train, X_test, y_train, y_test = train_test_split(mensagens, etiquetas, test_size=actual_test_size, random_state=42, stratify=etiquetas)\n",
        "            else:\n",
        "                 logging.warning(f\"Não é possível estratificar devido a poucas amostras na menor classe ({min_samples_per_class}). Usando split simples.\")\n",
        "                 X_train, X_test, y_train, y_test = train_test_split(mensagens, etiquetas, test_size=actual_test_size, random_state=42)\n",
        "        else:\n",
        "            X_train, X_test, y_train, y_test = mensagens, [], etiquetas, []\n",
        "\n",
        "        if not X_train:\n",
        "            logging.warning(\"Conjunto de treino vazio. Pulando treinamento.\")\n",
        "            return None\n",
        "\n",
        "        modelo.fit(X_train, y_train)\n",
        "        logging.info(\"Modelo local treinado com sucesso.\")\n",
        "        joblib.dump(modelo, MODELO_PKL_FILE)\n",
        "        logging.info(f\"Modelo local salvo em {MODELO_PKL_FILE}.\")\n",
        "\n",
        "        if X_test and y_test :\n",
        "            avaliar_modelo(modelo, X_test, y_test)\n",
        "        else:\n",
        "            logging.warning(\"Conjunto de teste vazio. Avaliação do modelo não realizada.\")\n",
        "\n",
        "        return modelo\n",
        "    except ValueError as ve:\n",
        "        logging.error(f\"Erro de valor durante o treinamento: {ve}\")\n",
        "        return None\n",
        "    except Exception as e:\n",
        "        logging.error(f\"Falha ao treinar ou salvar o modelo local: {e}\")\n",
        "        return None\n",
        "\n",
        "modelo_treinado_global = None\n",
        "try:\n",
        "    if os.path.exists(MODELO_PKL_FILE):\n",
        "        modelo_treinado_global = joblib.load(MODELO_PKL_FILE)\n",
        "        logging.info(f\"Modelo local carregado de {MODELO_PKL_FILE}.\")\n",
        "    else:\n",
        "        logging.info(f\"Arquivo de modelo {MODELO_PKL_FILE} não encontrado. Tentando treinar novo modelo.\")\n",
        "        modelo_treinado_global = treinar_modelo()\n",
        "except Exception as e:\n",
        "    logging.error(f\"Erro ao carregar modelo salvo de {MODELO_PKL_FILE}: {e}. Tentando treinar novo modelo.\")\n",
        "    modelo_treinado_global = treinar_modelo()\n",
        "\n",
        "# ---------- Funções de Classificação com diferentes IAs e Retries ------------\n",
        "def api_call_with_retry(api_function, *args, **kwargs):\n",
        "    for attempt in range(API_RETRY_ATTEMPTS):\n",
        "        try:\n",
        "            return api_function(*args, **kwargs)\n",
        "        except (openai.error.RateLimitError, openai.error.APIError, openai.error.ServiceUnavailableError, requests.exceptions.RequestException, genai.types.generation_types.StopCandidateException) as e:\n",
        "            logging.warning(f\"Erro de API na tentativa {attempt + 1}/{API_RETRY_ATTEMPTS} para {api_function.__name__}: {e}\")\n",
        "            if attempt + 1 == API_RETRY_ATTEMPTS:\n",
        "                logging.error(f\"Todas as {API_RETRY_ATTEMPTS} tentativas falharam para {api_function.__name__}.\")\n",
        "                raise\n",
        "            time.sleep(API_RETRY_DELAY * (attempt + 1))\n",
        "        except openai.error.AuthenticationError as auth_e:\n",
        "            logging.error(f\"Erro de autenticação com {api_function.__name__}: {auth_e}\")\n",
        "            raise\n",
        "        except Exception as general_exception:\n",
        "            if \"API_KEY_INVALID\" in str(general_exception) or \"PERMISSION_DENIED\" in str(general_exception) or (\"google.api_core.exceptions.PermissionDenied\" in str(type(general_exception))):\n",
        "                logging.error(f\"Erro de autenticação com {api_function.__name__} (possivelmente Gemini): {general_exception}\")\n",
        "                raise general_exception\n",
        "\n",
        "            logging.warning(f\"Erro de API (não autenticação) na tentativa {attempt + 1}/{API_RETRY_ATTEMPTS} para {api_function.__name__}: {general_exception}\")\n",
        "            if attempt + 1 == API_RETRY_ATTEMPTS:\n",
        "                raise\n",
        "            time.sleep(API_RETRY_DELAY * (attempt + 1))\n",
        "    return None\n",
        "\n",
        "def construir_prompt_comum(mensagem, exemplos_base):\n",
        "    prompt_exemplos_str = \"\".join([f'Mensagem: \"{ex[\"mensagem\"]}\"\\nClassificação: {ex[\"classificacao\"]}\\n\\n' for ex in exemplos_base[-10:]])\n",
        "    return (\n",
        "        \"Você é um assistente especializado em detetar fraudes e golpes em mensagens de texto. \"\n",
        "        \"Sua tarefa é classificar a mensagem fornecida pelo utilizador como 'Golpe' ou 'Não é golpe'. \"\n",
        "        \"Analise cuidadosamente o conteúdo da mensagem. Considere os seguintes exemplos:\\n\\n\"\n",
        "        f\"{prompt_exemplos_str}\"\n",
        "        f\"Agora, classifique esta mensagem: \\\"{mensagem}\\\"\\nResponda APENAS com 'Golpe' ou 'Não é golpe'.\\nClassificação:\"\n",
        "    )\n",
        "\n",
        "def _openai_api_call(model, messages, temperature, max_tokens):\n",
        "    return openai.ChatCompletion.create(model=model, messages=messages, temperature=temperature, max_tokens=max_tokens)\n",
        "\n",
        "def classificar_com_openai(mensagem, exemplos_base):\n",
        "    if not OPENAI_API_KEY:\n",
        "        logging.warning(\"OpenAI API Key não configurada.\")\n",
        "        return None, \"OpenAI (Não Configurado)\"\n",
        "    prompt_completo = construir_prompt_comum(mensagem, exemplos_base)\n",
        "    messages = [\n",
        "        {\"role\": \"system\", \"content\": \"Você é um assistente que deteta se mensagens são golpes ou não. Responda APENAS com 'Golpe' ou 'Não é golpe'.\"},\n",
        "        {\"role\": \"user\", \"content\": prompt_completo}\n",
        "    ]\n",
        "    try:\n",
        "        logging.info(f\"Enviando para OpenAI: '{mensagem[:30]}...'\")\n",
        "        resposta_obj = api_call_with_retry(_openai_api_call, model=\"gpt-4-turbo\", messages=messages, temperature=0, max_tokens=10)\n",
        "        if resposta_obj:\n",
        "            resultado_ia = resposta_obj.choices[0].message.content.strip().lower()\n",
        "            if resultado_ia in [\"golpe\", \"não é golpe\"]:\n",
        "                logging.info(f\"OpenAI classificou como: {resultado_ia}\")\n",
        "                return resultado_ia, \"OpenAI (GPT-4 Turbo)\"\n",
        "            logging.warning(f\"Resposta inesperada da OpenAI: '{resultado_ia}'.\")\n",
        "        return None, \"OpenAI (GPT-4 Turbo)\"\n",
        "    except openai.error.AuthenticationError as e:\n",
        "        logging.error(f\"Erro de autenticação com OpenAI: {e}\")\n",
        "        return \"Erro: Falha na autenticação com OpenAI.\", \"OpenAI (GPT-4 Turbo)\"\n",
        "    except Exception as e:\n",
        "        logging.error(f\"Erro ao classificar com OpenAI: {e}\")\n",
        "        return \"Erro: OpenAI API Error.\", \"OpenAI (GPT-4 Turbo)\"\n",
        "\n",
        "def _gemini_api_call(model_name, prompt):\n",
        "    if not GEMINI_API_KEY:\n",
        "        raise Exception(\"Chave da API Gemini não configurada para _gemini_api_call\")\n",
        "    model_gemini = genai.GenerativeModel(model_name)\n",
        "    return model_gemini.generate_content(prompt)\n",
        "\n",
        "def classificar_com_gemini(mensagem, exemplos_base):\n",
        "    if not GEMINI_API_KEY:\n",
        "        logging.warning(\"Gemini API Key não configurada.\")\n",
        "        return None, \"Gemini (Não Configurado)\"\n",
        "    prompt_completo = construir_prompt_comum(mensagem, exemplos_base)\n",
        "    try:\n",
        "        logging.info(f\"Enviando para Gemini: '{mensagem[:30]}...'\")\n",
        "        response = api_call_with_retry(_gemini_api_call, 'gemini-pro', prompt_completo)\n",
        "        if response:\n",
        "            resultado_ia = response.text.strip().lower()\n",
        "            if resultado_ia in [\"golpe\", \"não é golpe\"]:\n",
        "                logging.info(f\"Gemini classificou como: {resultado_ia}\")\n",
        "                return resultado_ia, \"Gemini (Pro)\"\n",
        "            if \"golpe\" in resultado_ia: return \"golpe\", \"Gemini (Pro)\"\n",
        "            if \"não é golpe\" in resultado_ia: return \"não é golpe\", \"Gemini (Pro)\"\n",
        "            logging.warning(f\"Resposta inesperada do Gemini: '{resultado_ia}'.\")\n",
        "        return None, \"Gemini (Pro)\"\n",
        "    except Exception as e:\n",
        "        logging.error(f\"Erro ao classificar com Gemini: {e}\")\n",
        "        if \"API_KEY_INVALID\" in str(e) or \"PERMISSION_DENIED\" in str(e) or (\"google.api_core.exceptions.PermissionDenied\" in str(type(e))):\n",
        "             return \"Erro: Falha na autenticação com Gemini.\", \"Gemini (Pro)\"\n",
        "        return \"Erro: Gemini API Error.\", \"Gemini (Pro)\"\n",
        "\n",
        "\n",
        "def classificar_com_multi_ia(mensagem):\n",
        "    exemplos_base = carregar_base()\n",
        "    classificacao_final = None\n",
        "    fonte_final = \"Nenhuma IA\"\n",
        "    erros_api = []\n",
        "\n",
        "    if OPENAI_API_KEY:\n",
        "        resultado_openai, fonte_openai = classificar_com_openai(mensagem, exemplos_base)\n",
        "        if resultado_openai and \"Erro:\" not in resultado_openai:\n",
        "            classificacao_final = resultado_openai\n",
        "            fonte_final = fonte_openai\n",
        "        elif resultado_openai and \"Erro:\" in resultado_openai:\n",
        "            erros_api.append(f\"{fonte_openai}: {resultado_openai.replace('Erro: ', '')}\")\n",
        "\n",
        "    if classificacao_final is None and GEMINI_API_KEY:\n",
        "        resultado_gemini, fonte_gemini = classificar_com_gemini(mensagem, exemplos_base)\n",
        "        if resultado_gemini and \"Erro:\" not in resultado_gemini:\n",
        "            classificacao_final = resultado_gemini\n",
        "            fonte_final = fonte_gemini\n",
        "        elif resultado_gemini and \"Erro:\" in resultado_gemini:\n",
        "            erros_api.append(f\"{fonte_gemini}: {resultado_gemini.replace('Erro: ', '')}\")\n",
        "\n",
        "    if classificacao_final: # Apenas se houver uma classificação válida (não None e não Erro)\n",
        "        base_atual = carregar_base()\n",
        "        base_atualizada = adicionar_nova_entrada(base_atual, mensagem, classificacao_final)\n",
        "        salvar_base(base_atualizada)\n",
        "        return f\"{classificacao_final} (Fonte: {fonte_final})\"\n",
        "    elif erros_api:\n",
        "        msg_erro = f\"Erro: Falha em serviços de IA ({'; '.join(erros_api)})\"\n",
        "        logging.error(msg_erro)\n",
        "        return msg_erro\n",
        "    else:\n",
        "        msg_incerto = \"Classificação incerta (IA). Por favor, tenha cuidado extra com esta mensagem.\"\n",
        "        logging.warning(f\"IA incerta para: '{mensagem[:30]}...'\")\n",
        "        return msg_incerto\n",
        "\n",
        "\n",
        "def classificar_mensagem_principal(mensagem):\n",
        "    global modelo_treinado_global\n",
        "\n",
        "    if modelo_treinado_global and hasattr(modelo_treinado_global, 'predict_proba'):\n",
        "        try:\n",
        "            probabilidades = modelo_treinado_global.predict_proba([mensagem])[0]\n",
        "            classes = modelo_treinado_global.classes_\n",
        "            confianca_maxima = np.max(probabilidades)\n",
        "\n",
        "            if confianca_maxima >= MODELO_LOCAL_CONFIANCA_LIMIAR:\n",
        "                predicao_idx = np.argmax(probabilidades)\n",
        "                predicao = classes[predicao_idx]\n",
        "                if predicao in [\"Golpe\", \"Não é golpe\"]:\n",
        "                    logging.info(f\"Classificação local (confiança: {confianca_maxima:.2f}) para '{mensagem[:30]}...': {predicao}\")\n",
        "                    return f\"{predicao} (Fonte: Modelo Local, Confiança: {confianca_maxima:.2f})\"\n",
        "                else:\n",
        "                    logging.warning(f\"Modelo local retornou classe inesperada '{predicao}'. Recorrendo à Multi-IA.\")\n",
        "            else:\n",
        "                logging.info(f\"Confiança do modelo local ({confianca_maxima:.2f}) abaixo do limiar ({MODELO_LOCAL_CONFIANCA_LIMIAR}). Recorrendo à Multi-IA.\")\n",
        "        except Exception as e:\n",
        "            logging.error(f\"Erro ao classificar com modelo local ou obter probabilidades: {e}. Recorrendo à Multi-IA.\")\n",
        "    else:\n",
        "        logging.warning(\"Modelo local não treinado/carregado ou não suporta predict_proba. Recorrendo à Multi-IA.\")\n",
        "\n",
        "    resultado_ia = classificar_com_multi_ia(mensagem)\n",
        "\n",
        "    if \"Erro:\" in resultado_ia and modelo_treinado_global and hasattr(modelo_treinado_global, 'predict'):\n",
        "        logging.warning(f\"Todas as IAs falharam. Usando modelo local como último recurso para '{mensagem[:30]}...'.\")\n",
        "        try:\n",
        "            predicao_fallback = modelo_treinado_global.predict([mensagem])[0]\n",
        "            if predicao_fallback in [\"Golpe\", \"Não é golpe\"]:\n",
        "                 return f\"{predicao_fallback} (Fonte: Modelo Local - Fallback IA)\"\n",
        "        except Exception as e_fallback:\n",
        "            logging.error(f\"Erro no fallback para modelo local: {e_fallback}\")\n",
        "            return resultado_ia\n",
        "\n",
        "    return resultado_ia\n",
        "\n",
        "\n",
        "# ---------- Web Scraping do ReclameAqui ------------\n",
        "def coletar_reclameaqui(termo=\"golpe pix\", paginas=1):\n",
        "    base_url = \"https://www.reclameaqui.com.br/busca/\"\n",
        "    resultados_scraping = []\n",
        "    headers = {\"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\"}\n",
        "    logging.info(f\"Scraping ReclameAqui: '{termo}', {paginas} pág.\")\n",
        "    for pagina in range(1, paginas + 1):\n",
        "        url = f\"{base_url}?query={requests.utils.quote(termo)}&page={pagina}\"\n",
        "        try:\n",
        "            resp = requests.get(url, headers=headers, timeout=15)\n",
        "            resp.raise_for_status()\n",
        "            soup = BeautifulSoup(resp.text, \"html.parser\")\n",
        "            posts = soup.select('a[data-testid=\"complaint-title\"], p[data-testid=\"complaint-description\"]')\n",
        "            if not posts: break\n",
        "            for p in posts:\n",
        "                texto = p.get_text(separator=\" \", strip=True)\n",
        "                if texto and len(texto.split()) > 10 and len(texto) < 1000:\n",
        "                    resultados_scraping.append(texto)\n",
        "            time.sleep(API_RETRY_DELAY)\n",
        "        except requests.exceptions.RequestException as e:\n",
        "            logging.warning(f\"Erro scraping ReclameAqui (pág {pagina}): {e}\")\n",
        "            break\n",
        "        except Exception as e:\n",
        "            logging.warning(f\"Erro inesperado scraping ReclameAqui (pág {pagina}): {e}\")\n",
        "            break\n",
        "    logging.info(f\"Scraping ReclameAqui concluído. {len(resultados_scraping)} textos.\")\n",
        "    return resultados_scraping\n",
        "\n",
        "# ---------- Atualização e Retreinamento Automático ------------\n",
        "def atualizar_e_treinar_automaticamente():\n",
        "    global modelo_treinado_global\n",
        "    logging.info(\"[AGENDADOR] Iniciando atualização e retreinamento.\")\n",
        "    base_existente = carregar_base()\n",
        "    novos_textos_raspados = coletar_reclameaqui(termo=\"golpe whatsapp\", paginas=1)\n",
        "\n",
        "    mensagens_realmente_novas = [\n",
        "        msg for msg in novos_textos_raspados\n",
        "        if not any(hashlib.sha256(msg.encode(\"utf-8\")).hexdigest() == hashlib.sha256(d[\"mensagem\"].encode(\"utf-8\")).hexdigest() for d in base_existente)\n",
        "    ]\n",
        "    logging.info(f\"[AGENDADOR] Novas mensagens únicas do ReclameAqui: {len(mensagens_realmente_novas)}.\")\n",
        "\n",
        "    if mensagens_realmente_novas:\n",
        "        for i, msg_nova in enumerate(mensagens_realmente_novas):\n",
        "            if i >= 2:\n",
        "                logging.info(f\"[AGENDADOR] Limite de {i} mensagens para IA atingido neste ciclo.\")\n",
        "                break\n",
        "            logging.info(f\"[AGENDADOR] Classificando msg raspada ({i+1}/{len(mensagens_realmente_novas)}) com Multi-IA: '{msg_nova[:30]}...'\")\n",
        "            classificacao_multi_ia = classificar_com_multi_ia(msg_nova)\n",
        "            if \"Erro:\" in classificacao_multi_ia:\n",
        "                logging.warning(f\"[AGENDADOR] Falha ao classificar '{msg_nova[:30]}...' com Multi-IA.\")\n",
        "\n",
        "    modelo_atualizado = treinar_modelo()\n",
        "    if modelo_atualizado:\n",
        "        modelo_treinado_global = modelo_atualizado\n",
        "        logging.info(\"[AGENDADOR] Modelo local re-treinado e atualizado.\")\n",
        "    else:\n",
        "        logging.warning(\"[AGENDADOR] Falha ao re-treinar modelo local após coleta.\")\n",
        "    logging.info(\"[AGENDADOR] Tarefa de atualização e retreinamento concluída.\")\n",
        "\n",
        "# ---------- Interface Flask (Rotas) ------------\n",
        "@app.route(\"/\", methods=[\"GET\", \"POST\"])\n",
        "def home():\n",
        "    global modelo_treinado_global\n",
        "    resultado_final_completo = None\n",
        "    mensagem_submetida = request.form.get(\"mensagem\", \"\").strip() if request.method == \"POST\" else request.args.get(\"mensagem\", \"\")\n",
        "    classificacao_pura_para_feedback = None\n",
        "\n",
        "    if request.method == \"POST\":\n",
        "        feedback_usuario = request.form.get(\"feedback\")\n",
        "        classificacao_anterior_pura_form = request.form.get(\"classificacao_anterior_pura\")\n",
        "        correcao_feedback = request.form.get(\"correcao_feedback\")\n",
        "\n",
        "        logging.info(f\"POST data: mensagem='{mensagem_submetida[:50]}...', feedback='{feedback_usuario}', class_ant_pura='{classificacao_anterior_pura_form}', correcao_feed='{correcao_feedback}'\")\n",
        "\n",
        "        if feedback_usuario and mensagem_submetida and classificacao_anterior_pura_form:\n",
        "            base_atual = carregar_base()\n",
        "            classificacao_para_salvar = \"\"\n",
        "            if feedback_usuario == \"nao\" and correcao_feedback:\n",
        "                classificacao_para_salvar = correcao_feedback\n",
        "                resultado_final_completo = f\"Obrigado pelo feedback! A mensagem foi reclassificada como: {classificacao_para_salvar}.\"\n",
        "                logging.info(f\"Feedback 'Não' com correção para '{mensagem_submetida[:30]}...'. Anterior: '{classificacao_anterior_pura_form}', Corrigida para: '{classificacao_para_salvar}'.\")\n",
        "            elif feedback_usuario == \"sim\":\n",
        "                classificacao_para_salvar = classificacao_anterior_pura_form\n",
        "                resultado_final_completo = f\"Obrigado por confirmar! A classificação '{classificacao_para_salvar}' foi mantida.\"\n",
        "                logging.info(f\"Feedback 'Sim' para '{mensagem_submetida[:30]}...'. Classificação confirmada: '{classificacao_para_salvar}'.\")\n",
        "\n",
        "            if classificacao_para_salvar:\n",
        "                logging.info(f\"Salvando feedback. Mensagem: '{mensagem_submetida[:30]}', Classificação para salvar: '{classificacao_para_salvar}'\")\n",
        "                base_atualizada = adicionar_nova_entrada(base_atual, mensagem_submetida, classificacao_para_salvar)\n",
        "                salvar_base(base_atualizada)\n",
        "                modelo_novo = treinar_modelo()\n",
        "                if modelo_novo:\n",
        "                    modelo_treinado_global = modelo_novo\n",
        "            # Após o feedback, não definimos classificacao_pura_para_feedback para evitar que os botões de feedback apareçam novamente para a mensagem de agradecimento.\n",
        "\n",
        "        elif mensagem_submetida and not feedback_usuario:\n",
        "            logging.info(f\"Nova mensagem para análise: '{mensagem_submetida[:30]}...'\")\n",
        "            resultado_final_completo = classificar_mensagem_principal(mensagem_submetida)\n",
        "            logging.info(f\"Resultado da classificação para '{mensagem_submetida[:30]}...': {resultado_final_completo}\")\n",
        "\n",
        "            # Define classificacao_pura_para_feedback APENAS se for uma classificação válida\n",
        "            if resultado_final_completo and isinstance(resultado_final_completo, str) and \\\n",
        "               not any(keyword in resultado_final_completo.lower() for keyword in [\"erro:\", \"classificação incerta\", \"obrigado pelo\", \"obrigado por confirmar\"]):\n",
        "                if \"não é golpe\" in resultado_final_completo.lower():\n",
        "                    classificacao_pura_para_feedback = \"Não é golpe\"\n",
        "                elif \"golpe\" in resultado_final_completo.lower() : # Garante que \"golpe\" não está em \"não é golpe\"\n",
        "                    classificacao_pura_para_feedback = \"Golpe\"\n",
        "\n",
        "    logging.info(f\"Para template: resultado_completo='{resultado_final_completo}', msg_submetida='{mensagem_submetida[:30]}...', class_pura_feedback='{classificacao_pura_para_feedback}'\")\n",
        "    return render_template(\"index.html\",\n",
        "                           resultado_classificacao_completo=resultado_final_completo,\n",
        "                           mensagem_submetida=mensagem_submetida,\n",
        "                           classificacao_pura_para_feedback=classificacao_pura_para_feedback)\n",
        "\n",
        "\n",
        "@app.route(\"/api/v1/classificar\", methods=[\"POST\"])\n",
        "def api_classificar():\n",
        "    try:\n",
        "        dados_requisicao = request.json\n",
        "        if not dados_requisicao or \"mensagem\" not in dados_requisicao:\n",
        "            return jsonify({\"erro\": \"Payload JSON inválido ou 'mensagem' não fornecida.\"}), 400\n",
        "        mensagem_api = dados_requisicao.get(\"mensagem\")\n",
        "        if not isinstance(mensagem_api, str) or not mensagem_api.strip():\n",
        "            return jsonify({\"erro\": \"'mensagem' deve ser uma string não vazia.\"}), 400\n",
        "\n",
        "        resultado_api_completo = classificar_mensagem_principal(mensagem_api)\n",
        "\n",
        "        classificacao_pura_api = \"incerta\"\n",
        "        fonte_api = \"desconhecida\"\n",
        "        if resultado_api_completo:\n",
        "            if \"Golpe\" in resultado_api_completo and \"Não é golpe\" not in resultado_api_completo: classificacao_pura_api = \"Golpe\"\n",
        "            elif \"Não é golpe\" in resultado_api_completo: classificacao_pura_api = \"Não é golpe\"\n",
        "\n",
        "            if \"(Fonte:\" in resultado_api_completo:\n",
        "                try:\n",
        "                    fonte_api = resultado_api_completo.split(\"(Fonte:\")[1].split(\")\")[0].strip()\n",
        "                except: pass\n",
        "\n",
        "        return jsonify({\n",
        "            \"mensagem\": mensagem_api,\n",
        "            \"classificacao\": classificacao_pura_api,\n",
        "            \"detalhe_classificacao\": resultado_api_completo,\n",
        "            \"fonte_principal\": fonte_api\n",
        "        })\n",
        "    except Exception as e:\n",
        "        logging.error(f\"Erro no endpoint /api/v1/classificar: {e}\")\n",
        "        return jsonify({\"erro\": \"Erro interno no servidor.\"}), 500\n",
        "\n",
        "\n",
        "@app.route(\"/api/v1/retrain\", methods=[\"POST\"])\n",
        "@require_api_key\n",
        "def rota_retreinar_modelo():\n",
        "    global modelo_treinado_global\n",
        "    logging.info(\"Requisição autenticada para re-treinar o modelo local via /api/v1/retrain.\")\n",
        "    modelo_novo = treinar_modelo()\n",
        "    if modelo_novo:\n",
        "        modelo_treinado_global = modelo_novo\n",
        "        return jsonify({\"mensagem\": \"Modelo local re-treinado com sucesso!\"}), 200\n",
        "    else:\n",
        "        return jsonify({\"erro\": \"Falha ao re-treinar o modelo local. Verifique os logs.\"}), 500\n",
        "\n",
        "# ---------- Agendador ------------\n",
        "scheduler = BackgroundScheduler(daemon=True)\n",
        "try:\n",
        "    scheduler.add_job(atualizar_e_treinar_automaticamente, 'interval', hours=12)\n",
        "    scheduler.start()\n",
        "    logging.info(\"Agendador iniciado.\")\n",
        "except Exception as e:\n",
        "    logging.error(f\"Erro ao iniciar o agendador: {e}\")\n",
        "\n",
        "# ---------- Função para rodar a aplicação Flask com pyngrok ------------\n",
        "def try_run_app_with_ngrok(initial_port, max_retries=5):\n",
        "    port_to_try = initial_port\n",
        "    ngrok_tunnel = None\n",
        "    NGROK_TOKEN = os.getenv(\"NGROK_AUTHTOKEN\")\n",
        "    if NGROK_TOKEN:\n",
        "        try:\n",
        "            ngrok.set_auth_token(NGROK_TOKEN)\n",
        "            logging.info(\"Token Ngrok configurado.\")\n",
        "        except Exception as e_auth: logging.error(f\"Erro config token ngrok: {e_auth}\")\n",
        "    else: logging.warning(\"NGROK_AUTHTOKEN não encontrado.\")\n",
        "\n",
        "    for i in range(max_retries):\n",
        "        logging.info(f\"Tentando Flask porta {port_to_try} com ngrok (tentativa {i+1}/{max_retries}).\")\n",
        "        try:\n",
        "            s = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n",
        "            s.bind((\"0.0.0.0\", port_to_try))\n",
        "            s.close()\n",
        "            logging.info(f\"Porta {port_to_try} livre.\")\n",
        "            try:\n",
        "                for t in ngrok.get_tunnels():\n",
        "                    ngrok.disconnect(t.public_url)\n",
        "                    logging.info(f\"Túnel ngrok {t.public_url} desconectado.\")\n",
        "                ngrok.kill()\n",
        "                logging.info(\"Processo ngrok anterior finalizado.\")\n",
        "            except Exception as ng_clean_e:\n",
        "                logging.info(f\"Limpeza ngrok: {ng_clean_e}\")\n",
        "\n",
        "            ngrok_tunnel = ngrok.connect(port_to_try)\n",
        "            public_url = ngrok_tunnel.public_url\n",
        "            logging.info(f\"Túnel Ngrok: {public_url}\")\n",
        "            print(f\" * Aplicação GolpeGuard: {public_url}\")\n",
        "            app.run(host=\"0.0.0.0\", port=port_to_try, debug=False, use_reloader=False)\n",
        "            return\n",
        "        except OSError as e:\n",
        "            if e.errno == 98: # Address already in use\n",
        "                logging.warning(f\"Porta {port_to_try} em uso.\")\n",
        "                if ngrok_tunnel:\n",
        "                    try:\n",
        "                        ngrok.disconnect(ngrok_tunnel.public_url)\n",
        "                        ngrok.kill()\n",
        "                    except Exception as ed:\n",
        "                        logging.error(f\"Erro disconnect ngrok: {ed}\")\n",
        "                port_to_try += 1\n",
        "            else: # Outro OSError\n",
        "                logging.error(f\"Erro SO porta {port_to_try}: {e}\")\n",
        "                if ngrok_tunnel:\n",
        "                    try:\n",
        "                        ngrok.disconnect(ngrok_tunnel.public_url)\n",
        "                        ngrok.kill()\n",
        "                    except Exception as ed:\n",
        "                        logging.error(f\"Erro disconnect ngrok: {ed}\")\n",
        "                break # Sai do loop de tentativas de porta\n",
        "        except Exception as e: # Outros erros (incluindo do pyngrok)\n",
        "            logging.error(f\"Erro Flask/ngrok porta {port_to_try}: {e}\")\n",
        "            if \"ERR_NGROK_108\" in str(e) or \"ERR_NGROK_4018\" in str(e) or \"authentication failed\" in str(e).lower():\n",
        "                print(\"ERRO AUTENTICAÇÃO NGROK. Verifique NGROK_AUTHTOKEN e conta.\")\n",
        "                print(\"Certifique-se de que não há outras sessões ngrok ativas na sua conta: https://dashboard.ngrok.com/cloud-edge/agent-sessions\")\n",
        "                logging.error(\"Falha autenticação Ngrok. Verifique o token e sessões ativas no painel do ngrok.\")\n",
        "            if ngrok_tunnel:\n",
        "                try:\n",
        "                    ngrok.disconnect(ngrok_tunnel.public_url)\n",
        "                    ngrok.kill()\n",
        "                except Exception as ed:\n",
        "                    logging.error(f\"Erro disconnect ngrok: {ed}\")\n",
        "            # Só tenta outra porta se não for erro de autenticação do ngrok ou limite de sessão\n",
        "            if not (\"ERR_NGROK_108\" in str(e) or \"ERR_NGROK_4018\" in str(e) or \"authentication failed\" in str(e).lower()):\n",
        "                 port_to_try += 1\n",
        "            else: break # Para se for erro de autenticação/limite de sessão\n",
        "    logging.error(f\"Não foi possível iniciar Flask com ngrok após {max_retries} tentativas.\")\n",
        "    print(f\"ERRO: Não foi possível iniciar Flask com ngrok.\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    logging.info(\"Executando atualização e treinamento inicial...\")\n",
        "    try:\n",
        "        atualizar_e_treinar_automaticamente()\n",
        "    except Exception as e:\n",
        "        logging.error(f\"Erro na atualização e treinamento inicial: {e}\")\n",
        "\n",
        "    default_port = int(os.getenv(\"PORT\", 5005))\n",
        "    try_run_app_with_ngrok(initial_port=default_port)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ksoLW03EOq4Y",
        "outputId": "6ccc6b86-4176-4528-8afb-31b52d33035c"
      },
      "id": "ksoLW03EOq4Y",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:Chave da API OpenAI (OPENAI_API_KEY) não encontrada. Funcionalidade do ChatGPT desabilitada.\n",
            "WARNING:root:Chave da API Gemini (GEMINI_API_KEY) não encontrada. Funcionalidade do Gemini desabilitada.\n",
            "INFO:root:Modelo local carregado de modelo_golpe_guard.pkl.\n",
            "INFO:apscheduler.scheduler:Adding job tentatively -- it will be properly scheduled when the scheduler starts\n",
            "INFO:apscheduler.scheduler:Added job \"atualizar_e_treinar_automaticamente\" to job store \"default\"\n",
            "INFO:apscheduler.scheduler:Scheduler started\n",
            "INFO:root:Agendador iniciado.\n",
            "INFO:root:Executando atualização e treinamento inicial...\n",
            "INFO:root:[AGENDADOR] Iniciando atualização e retreinamento.\n",
            "INFO:root:Scraping ReclameAqui: 'golpe whatsapp', 1 pág.\n",
            "WARNING:root:Erro scraping ReclameAqui (pág 1): 403 Client Error: Forbidden for url: https://www.reclameaqui.com.br/busca/?query=golpe%20whatsapp&page=1\n",
            "INFO:root:Scraping ReclameAqui concluído. 0 textos.\n",
            "INFO:root:[AGENDADOR] Novas mensagens únicas do ReclameAqui: 0.\n",
            "INFO:root:Modelo local treinado com sucesso.\n",
            "INFO:root:Modelo local salvo em modelo_golpe_guard.pkl.\n",
            "INFO:root:Avaliação do modelo local: Acurácia=0.5000\n",
            "INFO:root:[AGENDADOR] Modelo local re-treinado e atualizado.\n",
            "INFO:root:[AGENDADOR] Tarefa de atualização e retreinamento concluída.\n",
            "WARNING:root:NGROK_AUTHTOKEN não encontrado.\n",
            "INFO:root:Tentando Flask porta 5005 com ngrok (tentativa 1/5).\n",
            "INFO:root:Porta 5005 livre.\n",
            "INFO:pyngrok.process.ngrok:t=2025-05-17T03:25:41+0000 lvl=info msg=\"no configuration paths supplied\"\n",
            "INFO:pyngrok.process.ngrok:t=2025-05-17T03:25:41+0000 lvl=info msg=\"using configuration at default config path\" path=/root/.config/ngrok/ngrok.yml\n",
            "INFO:pyngrok.process.ngrok:t=2025-05-17T03:25:41+0000 lvl=info msg=\"open config file\" path=/root/.config/ngrok/ngrok.yml err=nil\n",
            "INFO:pyngrok.process.ngrok:t=2025-05-17T03:25:41+0000 lvl=info msg=\"starting web service\" obj=web addr=127.0.0.1:4040 allow_hosts=[]\n",
            "INFO:pyngrok.process.ngrok:t=2025-05-17T03:25:41+0000 lvl=info msg=\"client session established\" obj=tunnels.session\n",
            "INFO:pyngrok.process.ngrok:t=2025-05-17T03:25:41+0000 lvl=info msg=\"tunnel session started\" obj=tunnels.session\n",
            "INFO:pyngrok.process:Killing ngrok process: 79538\n",
            "INFO:pyngrok.process.ngrok:t=2025-05-17T03:25:41+0000 lvl=info msg=start pg=/api/tunnels id=4e9b4b36fa80246a\n",
            "INFO:pyngrok.process.ngrok:t=2025-05-17T03:25:41+0000 lvl=info msg=end pg=/api/tunnels id=4e9b4b36fa80246a status=200 dur=338.586µs\n",
            "INFO:pyngrok.process.ngrok:t=2025-05-17T03:25:41+0000 lvl=info msg=start pg=/api/tunnels id=248515105ee64ff4\n",
            "INFO:pyngrok.process.ngrok:t=2025-05-17T03:25:41+0000 lvl=info msg=end pg=/api/tunnels id=248515105ee64ff4 status=200 dur=126.7µs\n",
            "INFO:pyngrok.process.ngrok:t=2025-05-17T03:25:41+0000 lvl=info msg=start pg=/api/tunnels id=4ec724615d886d7d\n",
            "INFO:pyngrok.process.ngrok:t=2025-05-17T03:25:41+0000 lvl=info msg=end pg=/api/tunnels id=4ec724615d886d7d status=200 dur=149.964µs\n",
            "INFO:root:Processo ngrok anterior finalizado.\n",
            "INFO:pyngrok.ngrok:Opening tunnel named: http-5005-8b572287-997e-457a-954e-e10d1f7f2d2b\n",
            "INFO:pyngrok.process.ngrok:t=2025-05-17T03:25:41+0000 lvl=info msg=\"no configuration paths supplied\"\n",
            "INFO:pyngrok.process.ngrok:t=2025-05-17T03:25:41+0000 lvl=info msg=\"using configuration at default config path\" path=/root/.config/ngrok/ngrok.yml\n",
            "INFO:pyngrok.process.ngrok:t=2025-05-17T03:25:41+0000 lvl=info msg=\"open config file\" path=/root/.config/ngrok/ngrok.yml err=nil\n",
            "INFO:pyngrok.process.ngrok:t=2025-05-17T03:25:41+0000 lvl=info msg=\"starting web service\" obj=web addr=127.0.0.1:4040 allow_hosts=[]\n",
            "INFO:pyngrok.process.ngrok:t=2025-05-17T03:25:41+0000 lvl=info msg=\"client session established\" obj=tunnels.session\n",
            "INFO:pyngrok.process.ngrok:t=2025-05-17T03:25:41+0000 lvl=info msg=\"tunnel session started\" obj=tunnels.session\n",
            "INFO:pyngrok.process.ngrok:t=2025-05-17T03:25:41+0000 lvl=info msg=start pg=/api/tunnels id=4e9b4b36fa80246a\n",
            "INFO:pyngrok.process.ngrok:t=2025-05-17T03:25:41+0000 lvl=info msg=end pg=/api/tunnels id=4e9b4b36fa80246a status=200 dur=529.837µs\n",
            "INFO:pyngrok.process.ngrok:t=2025-05-17T03:25:41+0000 lvl=info msg=start pg=/api/tunnels id=248515105ee64ff4\n",
            "INFO:pyngrok.process.ngrok:t=2025-05-17T03:25:41+0000 lvl=info msg=end pg=/api/tunnels id=248515105ee64ff4 status=200 dur=155.646µs\n",
            "INFO:pyngrok.process.ngrok:t=2025-05-17T03:25:41+0000 lvl=info msg=start pg=/api/tunnels id=4ec724615d886d7d\n",
            "INFO:pyngrok.process.ngrok:t=2025-05-17T03:25:41+0000 lvl=info msg=\"started tunnel\" obj=tunnels name=http-5005-8b572287-997e-457a-954e-e10d1f7f2d2b addr=http://localhost:5005 url=https://3e36-35-245-103-146.ngrok-free.app\n",
            "INFO:pyngrok.process.ngrok:t=2025-05-17T03:25:41+0000 lvl=info msg=end pg=/api/tunnels id=4ec724615d886d7d status=201 dur=39.217745ms\n",
            "INFO:root:Túnel Ngrok: https://3e36-35-245-103-146.ngrok-free.app\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " * Aplicação GolpeGuard: https://3e36-35-245-103-146.ngrok-free.app\n",
            " * Serving Flask app '__main__'\n",
            " * Debug mode: off\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:werkzeug:\u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n",
            " * Running on all addresses (0.0.0.0)\n",
            " * Running on http://127.0.0.1:5005\n",
            " * Running on http://172.28.0.12:5005\n",
            "INFO:werkzeug:\u001b[33mPress CTRL+C to quit\u001b[0m\n",
            "INFO:pyngrok.process.ngrok:t=2025-05-17T03:26:10+0000 lvl=info msg=\"join connections\" obj=join id=b439cf1d8ad5 l=127.0.0.1:5005 r=[2804:29b8:5078:9975:19d4:8ac6:13d0:f9c2]:59780\n",
            "INFO:root:Para template: resultado_completo='None', msg_submetida='...', class_pura_feedback='None'\n",
            "INFO:werkzeug:127.0.0.1 - - [17/May/2025 03:26:10] \"GET / HTTP/1.1\" 200 -\n",
            "INFO:pyngrok.process.ngrok:t=2025-05-17T03:26:11+0000 lvl=info msg=\"join connections\" obj=join id=d8e090f73154 l=127.0.0.1:5005 r=[2804:29b8:5078:9975:19d4:8ac6:13d0:f9c2]:59780\n",
            "INFO:werkzeug:127.0.0.1 - - [17/May/2025 03:26:11] \"\u001b[33mGET /favicon.ico HTTP/1.1\u001b[0m\" 404 -\n",
            "INFO:pyngrok.process.ngrok:t=2025-05-17T03:26:34+0000 lvl=info msg=\"join connections\" obj=join id=1f1e17aa0794 l=127.0.0.1:5005 r=[2804:29b8:5078:9975:19d4:8ac6:13d0:f9c2]:59780\n",
            "INFO:root:POST data: mensagem='Olá Alexandre!\n",
            "\n",
            "Eu vi que você solicitou o compa...', feedback='None', class_ant_pura='None', correcao_feed='None'\n",
            "INFO:root:Nova mensagem para análise: 'Olá Alexandre!\n",
            "\n",
            "Eu vi que vo...'\n",
            "INFO:root:Confiança do modelo local (0.62) abaixo do limiar (0.7). Recorrendo à Multi-IA.\n",
            "WARNING:root:IA incerta para: 'Olá Alexandre!\n",
            "\n",
            "Eu vi que vo...'\n",
            "INFO:root:Resultado da classificação para 'Olá Alexandre!\n",
            "\n",
            "Eu vi que vo...': Classificação incerta (IA). Por favor, tenha cuidado extra com esta mensagem.\n",
            "INFO:root:Para template: resultado_completo='Classificação incerta (IA). Por favor, tenha cuidado extra com esta mensagem.', msg_submetida='Olá Alexandre!\n",
            "\n",
            "Eu vi que vo...', class_pura_feedback='None'\n",
            "INFO:werkzeug:127.0.0.1 - - [17/May/2025 03:26:34] \"POST / HTTP/1.1\" 200 -\n",
            "INFO:pyngrok.process.ngrok:t=2025-05-17T03:26:54+0000 lvl=info msg=\"join connections\" obj=join id=64a3650d5f30 l=127.0.0.1:5005 r=[2804:29b8:5078:9975:19d4:8ac6:13d0:f9c2]:59780\n",
            "INFO:root:POST data: mensagem='📣 Bora trazer mais gente pra SCT?\n",
            "Lembra da campa...', feedback='None', class_ant_pura='None', correcao_feed='None'\n",
            "INFO:root:Nova mensagem para análise: '📣 Bora trazer mais gente pra S...'\n",
            "INFO:root:Classificação local (confiança: 0.77) para '📣 Bora trazer mais gente pra S...': Não é golpe\n",
            "INFO:root:Resultado da classificação para '📣 Bora trazer mais gente pra S...': Não é golpe (Fonte: Modelo Local, Confiança: 0.77)\n",
            "INFO:root:Para template: resultado_completo='Não é golpe (Fonte: Modelo Local, Confiança: 0.77)', msg_submetida='📣 Bora trazer mais gente pra S...', class_pura_feedback='Não é golpe'\n",
            "INFO:werkzeug:127.0.0.1 - - [17/May/2025 03:26:54] \"POST / HTTP/1.1\" 200 -\n",
            "INFO:pyngrok.process.ngrok:t=2025-05-17T03:27:53+0000 lvl=info msg=\"join connections\" obj=join id=8d08f0f4a3e3 l=127.0.0.1:5005 r=[2804:29b8:5078:9975:19d4:8ac6:13d0:f9c2]:59780\n",
            "INFO:root:POST data: mensagem='BRASIL\n",
            "MINISTÉRIO DA FAZENDA\n",
            "RECEITA FEDERAL\n",
            "NO...', feedback='None', class_ant_pura='None', correcao_feed='None'\n",
            "INFO:root:Nova mensagem para análise: 'BRASIL\n",
            "...'\n",
            "INFO:root:Confiança do modelo local (0.62) abaixo do limiar (0.7). Recorrendo à Multi-IA.\n",
            "WARNING:root:IA incerta para: 'BRASIL\n",
            "...'\n",
            "INFO:root:Resultado da classificação para 'BRASIL\n",
            "...': Classificação incerta (IA). Por favor, tenha cuidado extra com esta mensagem.\n",
            "INFO:root:Para template: resultado_completo='Classificação incerta (IA). Por favor, tenha cuidado extra com esta mensagem.', msg_submetida='BRASIL\n",
            "...', class_pura_feedback='None'\n",
            "INFO:werkzeug:127.0.0.1 - - [17/May/2025 03:27:53] \"POST / HTTP/1.1\" 200 -\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Célula para Salvar o templates/index.html no Google Colab\n",
        "\n",
        "import os\n",
        "\n",
        "# Cria o diretório 'templates' se não existir\n",
        "# Esta linha deve estar corretamente indentada (sem espaços à esquerda,\n",
        "# se for o início de um bloco de código na célula)\n",
        "if not os.path.exists(\"templates\"):\n",
        "    os.makedirs(\"templates\")\n",
        "    print(\"Diretório 'templates' criado.\")\n",
        "\n",
        "# O conteúdo HTML é atribuído a esta variável.\n",
        "# A linha html_content = \"\"\" deve estar corretamente indentada.\n",
        "html_content = \"\"\"\n",
        "<!DOCTYPE html>\n",
        "<html lang=\"pt-BR\">\n",
        "<head>\n",
        "    <meta charset=\"UTF-8\" />\n",
        "    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n",
        "    <title>GolpeGuard Turbo Inteligente</title>\n",
        "    <script src=\"https://cdn.tailwindcss.com\"></script>\n",
        "    <style>\n",
        "        body {\n",
        "            font-family: 'Inter', sans-serif;\n",
        "        }\n",
        "        .loader {\n",
        "            border: 4px solid #f3f3f3; /* Light grey */\n",
        "            border-top: 4px solid #3498db; /* Blue */\n",
        "            border-radius: 50%;\n",
        "            width: 30px;\n",
        "            height: 30px;\n",
        "            animation: spin 1s linear infinite;\n",
        "            margin: 1rem auto;\n",
        "        }\n",
        "        @keyframes spin {\n",
        "            0% { transform: rotate(0deg); }\n",
        "            100% { transform: rotate(360deg); }\n",
        "        }\n",
        "    </style>\n",
        "    <link href=\"https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&display=swap\" rel=\"stylesheet\">\n",
        "</head>\n",
        "<body class=\"bg-gradient-to-br from-slate-900 to-slate-700 text-gray-100 min-h-screen flex flex-col items-center justify-center p-4\">\n",
        "\n",
        "    <div class=\"bg-slate-800 shadow-2xl rounded-xl p-6 md:p-10 w-full max-w-2xl\">\n",
        "        <header class=\"text-center mb-8\">\n",
        "            <h1 class=\"text-4xl font-bold text-sky-400 mb-2\">\n",
        "                <span role=\"img\" aria-label=\"Escudo de Proteção\" class=\"mr-2\">🛡️</span>GolpeGuard TI\n",
        "            </h1>\n",
        "            <p class=\"text-lg text-slate-300\">Seu detector de golpes inteligente, agora com Turbo!</p>\n",
        "        </header>\n",
        "\n",
        "        <form method=\"POST\" id=\"analysis-form\" class=\"space-y-6\">\n",
        "            <div>\n",
        "                <label for=\"mensagem\" class=\"block text-sm font-medium text-sky-300 mb-1\">Mensagem para Análise:</label>\n",
        "                <textarea name=\"mensagem\" id=\"mensagem\" rows=\"6\"\n",
        "                          class=\"w-full p-3 bg-slate-700 border border-slate-600 rounded-lg shadow-sm focus:ring-2 focus:ring-sky-500 focus:border-sky-500 placeholder-slate-400 text-gray-100 transition duration-150 ease-in-out\"\n",
        "                          placeholder=\"Cole aqui a mensagem suspeita que você recebeu por SMS, WhatsApp, e-mail, etc...\">{{ mensagem_submetida if mensagem_submetida else '' }}</textarea>\n",
        "            </div>\n",
        "\n",
        "            <div class=\"text-center\">\n",
        "                <button type=\"submit\" id=\"submit-button\"\n",
        "                        class=\"w-full sm:w-auto bg-sky-600 hover:bg-sky-700 text-white font-semibold py-3 px-6 rounded-lg shadow-md focus:outline-none focus:ring-2 focus:ring-sky-500 focus:ring-opacity-50 transition duration-150 ease-in-out transform hover:scale-105\">\n",
        "                    Analisar Mensagem\n",
        "                </button>\n",
        "            </div>\n",
        "        </form>\n",
        "\n",
        "        <div id=\"loader\" class=\"loader\" style=\"display: none;\"></div>\n",
        "\n",
        "        {% if resultado_classificacao_completo %}\n",
        "            <div id=\"resultado-bloco\" class=\"mt-8 p-6 rounded-lg shadow-lg border\n",
        "                {% if 'Golpe' in resultado_classificacao_completo and 'Não é golpe' not in resultado_classificacao_completo %} bg-red-800 border-red-600\n",
        "                {% elif 'Não é golpe' in resultado_classificacao_completo %} bg-green-800 border-green-600\n",
        "                {% elif 'Obrigado' in resultado_classificacao_completo %} bg-sky-800 border-sky-600\n",
        "                {% else %} bg-yellow-800 border-yellow-600\n",
        "                {% endif %}\">\n",
        "\n",
        "                <h2 class=\"text-2xl font-semibold mb-3 text-center\">\n",
        "                    {% if 'Golpe' in resultado_classificacao_completo and 'Não é golpe' not in resultado_classificacao_completo %} 🚨 Potencial Golpe!\n",
        "                    {% elif 'Não é golpe' in resultado_classificacao_completo %} ✅ Parece Seguro.\n",
        "                    {% elif 'Obrigado' in resultado_classificacao_completo %} ℹ️ Status\n",
        "                    {% else %} ⚠️ Atenção!\n",
        "                    {% endif %}\n",
        "                </h2>\n",
        "                <p class=\"text-lg text-center mb-4\">{{ resultado_classificacao_completo }}</p>\n",
        "\n",
        "                {% if classificacao_pura_para_feedback and not 'Obrigado' in resultado_classificacao_completo %}\n",
        "                    <div class=\"mt-6 border-t border-slate-600 pt-4\">\n",
        "                        <p class=\"text-center text-sm text-slate-300 mb-2\">A classificação está correta?</p>\n",
        "                        <form method=\"POST\" id=\"feedback-form\" class=\"space-y-3\">\n",
        "                            <input type=\"hidden\" name=\"mensagem\" value=\"{{ mensagem_submetida }}\">\n",
        "                            <input type=\"hidden\" name=\"classificacao_anterior_pura\" value=\"{{ classificacao_pura_para_feedback }}\">\n",
        "\n",
        "                            <div class=\"flex justify-center items-center space-x-3\">\n",
        "                                <button name=\"feedback\" value=\"sim\" type=\"submit\"\n",
        "                                        class=\"bg-green-600 hover:bg-green-700 text-white font-medium py-2 px-4 rounded-md text-sm transition\">\n",
        "                                    👍 Sim\n",
        "                                </button>\n",
        "                                <button name=\"feedback\" value=\"nao\" type=\"button\" id=\"feedback-nao-btn\"\n",
        "                                        class=\"bg-red-600 hover:bg-red-700 text-white font-medium py-2 px-4 rounded-md text-sm transition\">\n",
        "                                    👎 Não\n",
        "                                </button>\n",
        "                            </div>\n",
        "                            <div id=\"correcao-feedback-div\" class=\"mt-3 text-center feedback-options\" style=\"display: none;\">\n",
        "                                <p class=\"text-sm text-slate-300 mb-1\">Qual seria a classificação correta?</p>\n",
        "                                <label><input type=\"radio\" name=\"correcao_feedback\" value=\"Golpe\" required> Golpe</label>\n",
        "                                <label><input type=\"radio\" name=\"correcao_feedback\" value=\"Não é golpe\"> Não é golpe</label>\n",
        "                                <button type=\"submit\" id=\"submit-correcao-btn\" class=\"mt-2 bg-sky-600 hover:bg-sky-700 text-white font-medium py-1 px-3 rounded-md text-sm\">Enviar Correção</button>\n",
        "                            </div>\n",
        "                        </form>\n",
        "                    </div>\n",
        "                {% endif %}\n",
        "            </div>\n",
        "        {% endif %}\n",
        "\n",
        "        <footer class=\"mt-10 text-center text-xs text-slate-400\">\n",
        "            <p>&copy; 2024 GolpeGuard TI. Todos os direitos reservados.</p> <p class=\"mt-1\">Lembre-se: este é um sistema de auxílio. Sempre use o bom senso.</p>\n",
        "        </footer>\n",
        "    </div>\n",
        "\n",
        "    <script>\n",
        "        const analysisForm = document.getElementById('analysis-form');\n",
        "        const submitButton = document.getElementById('submit-button');\n",
        "        const loader = document.getElementById('loader');\n",
        "        const resultadoBloco = document.getElementById('resultado-bloco');\n",
        "        const feedbackNaoBtn = document.getElementById('feedback-nao-btn');\n",
        "        const correcaoFeedbackDiv = document.getElementById('correcao-feedback-div');\n",
        "        const feedbackForm = document.getElementById('feedback-form');\n",
        "\n",
        "        if (analysisForm) {\n",
        "            analysisForm.addEventListener('submit', function(event) {\n",
        "                const mensagemTextarea = document.getElementById('mensagem');\n",
        "                if (mensagemTextarea && mensagemTextarea.value.trim() !== '') {\n",
        "                    if (submitButton) {\n",
        "                        submitButton.disabled = true;\n",
        "                        submitButton.innerHTML = 'Analisando... <span class=\"animate-pulse\">⏳</span>';\n",
        "                    }\n",
        "                    if (loader) loader.style.display = 'block';\n",
        "                    if (resultadoBloco) resultadoBloco.style.display = 'none';\n",
        "                } else {\n",
        "                    event.preventDefault();\n",
        "                }\n",
        "            });\n",
        "        }\n",
        "\n",
        "        if (feedbackNaoBtn) {\n",
        "            feedbackNaoBtn.addEventListener('click', function() {\n",
        "                if (correcaoFeedbackDiv) correcaoFeedbackDiv.style.display = 'block';\n",
        "                let feedbackInput = feedbackForm.querySelector('input[name=\"feedback\"]');\n",
        "                if (!feedbackInput) {\n",
        "                    feedbackInput = document.createElement('input');\n",
        "                    feedbackInput.type = 'hidden';\n",
        "                    feedbackInput.name = 'feedback';\n",
        "                    feedbackForm.appendChild(feedbackInput);\n",
        "                }\n",
        "                feedbackInput.value = 'nao';\n",
        "            });\n",
        "        }\n",
        "\n",
        "        window.addEventListener('DOMContentLoaded', () => {\n",
        "            const resultadoBlocoPresente = document.getElementById('resultado-bloco');\n",
        "            const loaderElement = document.getElementById('loader');\n",
        "            if (resultadoBlocoPresente) { // Se o Jinja renderizou o bloco de resultado\n",
        "                resultadoBlocoPresente.style.display = 'block';\n",
        "                if (loaderElement) loaderElement.style.display = 'none';\n",
        "                if (submitButton) {\n",
        "                    submitButton.disabled = false;\n",
        "                    submitButton.innerHTML = 'Analisar Mensagem';\n",
        "                }\n",
        "            }\n",
        "        });\n",
        "    </script>\n",
        "</body>\n",
        "</html>\n",
        "\"\"\"\n",
        "\n",
        "# As linhas with open(...) e print(...) devem estar corretamente indentadas\n",
        "# em relação ao início da célula ou ao bloco if anterior.\n",
        "# Se não houver um 'if' antes, elas devem estar sem espaços à esquerda.\n",
        "with open(\"templates/index.html\", \"w\", encoding=\"utf-8\") as f:\n",
        "    f.write(html_content)\n",
        "print(\"Arquivo templates/index.html salvo.\")\n"
      ],
      "metadata": {
        "id": "5fkk8grdM3nq"
      },
      "id": "5fkk8grdM3nq",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "<!DOCTYPE html>\n",
        "<html lang=\"pt-BR\">\n",
        "<head>\n",
        "    <meta charset=\"UTF-8\" />\n",
        "    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n",
        "    <title>GolpeGuard Turbo Inteligente</title>\n",
        "    <script src=\"https://cdn.tailwindcss.com\"></script>\n",
        "    <style>\n",
        "        body {\n",
        "            font-family: 'Inter', sans-serif;\n",
        "        }\n",
        "        .loader {\n",
        "            border: 4px solid #f3f3f3; /* Light grey */\n",
        "            border-top: 4px solid #3498db; /* Blue */\n",
        "            border-radius: 50%;\n",
        "            width: 30px;\n",
        "            height: 30px;\n",
        "            animation: spin 1s linear infinite;\n",
        "            margin: 1rem auto;\n",
        "        }\n",
        "        @keyframes spin {\n",
        "            0% { transform: rotate(0deg); }\n",
        "            100% { transform: rotate(360deg); }\n",
        "        }\n",
        "    </style>\n",
        "    <link href=\"https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&display=swap\" rel=\"stylesheet\">\n",
        "</head>\n",
        "<body class=\"bg-gradient-to-br from-slate-900 to-slate-700 text-gray-100 min-h-screen flex flex-col items-center justify-center p-4\">\n",
        "\n",
        "    <div class=\"bg-slate-800 shadow-2xl rounded-xl p-6 md:p-10 w-full max-w-2xl\">\n",
        "        <header class=\"text-center mb-8\">\n",
        "            <h1 class=\"text-4xl font-bold text-sky-400 mb-2\">\n",
        "                <span role=\"img\" aria-label=\"Escudo de Proteção\" class=\"mr-2\">🛡️</span>GolpeGuard TI\n",
        "            </h1>\n",
        "            <p class=\"text-lg text-slate-300\">Seu detector de golpes inteligente, agora com Turbo!</p>\n",
        "        </header>\n",
        "\n",
        "        <form method=\"POST\" id=\"analysis-form\" class=\"space-y-6\">\n",
        "            <div>\n",
        "                <label for=\"mensagem\" class=\"block text-sm font-medium text-sky-300 mb-1\">Mensagem para Análise:</label>\n",
        "                <textarea name=\"mensagem\" id=\"mensagem\" rows=\"6\"\n",
        "                          class=\"w-full p-3 bg-slate-700 border border-slate-600 rounded-lg shadow-sm focus:ring-2 focus:ring-sky-500 focus:border-sky-500 placeholder-slate-400 text-gray-100 transition duration-150 ease-in-out\"\n",
        "                          placeholder=\"Cole aqui a mensagem suspeita que você recebeu por SMS, WhatsApp, e-mail, etc...\">{{ mensagem_submetida if mensagem_submetida else '' }}</textarea>\n",
        "            </div>\n",
        "\n",
        "            <div class=\"text-center\">\n",
        "                <button type=\"submit\" id=\"submit-button\"\n",
        "                        class=\"w-full sm:w-auto bg-sky-600 hover:bg-sky-700 text-white font-semibold py-3 px-6 rounded-lg shadow-md focus:outline-none focus:ring-2 focus:ring-sky-500 focus:ring-opacity-50 transition duration-150 ease-in-out transform hover:scale-105\">\n",
        "                    Analisar Mensagem\n",
        "                </button>\n",
        "            </div>\n",
        "        </form>\n",
        "\n",
        "        <div id=\"loader\" class=\"loader\" style=\"display: none;\"></div>\n",
        "\n",
        "        {% if resultado_classificacao %}\n",
        "            <div id=\"resultado-bloco\" class=\"mt-8 p-6 rounded-lg shadow-lg\n",
        "                {% if 'Golpe' in resultado_classificacao %} bg-red-700 border-red-500\n",
        "                {% elif 'Não é golpe' in resultado_classificacao %} bg-green-700 border-green-500\n",
        "                {% elif 'Obrigado pelo feedback' in resultado_classificacao %} bg-sky-700 border-sky-500\n",
        "                {% else %} bg-yellow-700 border-yellow-500\n",
        "                {% endif %} border\" style=\"display: block;\"> {/* Adicionado style=\"display: block;\" para garantir visibilidade se renderizado */}\n",
        "\n",
        "                <h2 class=\"text-2xl font-semibold mb-3 text-center\">\n",
        "                    {% if 'Golpe' in resultado_classificacao %}\n",
        "                        <span role=\"img\" aria-label=\"Alerta Vermelho\">🚨</span> Potencial Golpe Detectado!\n",
        "                    {% elif 'Não é golpe' in resultado_classificacao %}\n",
        "                        <span role=\"img\" aria-label=\"Verificado\">✅</span> Parece Seguro.\n",
        "                    {% elif 'Obrigado pelo feedback' in resultado_classificacao %}\n",
        "                        <span role=\"img\" aria-label=\"Informação\">ℹ️</span> Status\n",
        "                    {% else %}\n",
        "                        <span role=\"img\" aria-label=\"Atenção\">⚠️</span> Atenção!\n",
        "                    {% endif %}\n",
        "                </h2>\n",
        "                <p class=\"text-lg text-center mb-4\">{{ resultado_classificacao }}</p>\n",
        "\n",
        "                {% if classificacao_para_feedback and not 'Obrigado pelo feedback' in resultado_classificacao %}\n",
        "                    <div class=\"mt-6 border-t border-slate-500 pt-4\">\n",
        "                        <p class=\"text-center text-sm text-slate-300 mb-2\">A classificação está correta?</p>\n",
        "                        <form method=\"POST\" class=\"flex justify-center items-center space-x-3\">\n",
        "                            <input type=\"hidden\" name=\"mensagem\" value=\"{{ mensagem_submetida }}\">\n",
        "                            <input type=\"hidden\" name=\"classificacao_anterior\" value=\"{{ classificacao_para_feedback }}\">\n",
        "\n",
        "                            <button name=\"feedback\" value=\"sim\" type=\"submit\"\n",
        "                                    class=\"bg-green-600 hover:bg-green-700 text-white font-medium py-2 px-4 rounded-md text-sm transition duration-150 ease-in-out\">\n",
        "                                👍 Sim\n",
        "                            </button>\n",
        "                            <button name=\"feedback\" value=\"nao\" type=\"submit\"\n",
        "                                    class=\"bg-red-600 hover:bg-red-700 text-white font-medium py-2 px-4 rounded-md text-sm transition duration-150 ease-in-out\">\n",
        "                                👎 Não\n",
        "                            </button>\n",
        "                        </form>\n",
        "                    </div>\n",
        "                {% endif %}\n",
        "            </div>\n",
        "        {% endif %}\n",
        "\n",
        "        <footer class=\"mt-10 text-center text-xs text-slate-400\">\n",
        "            <p>&copy; 2024 GolpeGuard Turbo Inteligente. Todos os direitos reservados.</p>\n",
        "            <p class=\"mt-1\">Lembre-se: este é um sistema de auxílio. Sempre use o bom senso.</p>\n",
        "        </footer>\n",
        "    </div>\n",
        "\n",
        "    <script>\n",
        "        const analysisForm = document.getElementById('analysis-form');\n",
        "        const submitButton = document.getElementById('submit-button');\n",
        "        const loader = document.getElementById('loader');\n",
        "        const resultadoBloco = document.getElementById('resultado-bloco');\n",
        "\n",
        "        if (analysisForm) {\n",
        "            analysisForm.addEventListener('submit', function(event) {\n",
        "                const mensagemTextarea = document.getElementById('mensagem');\n",
        "                if (mensagemTextarea && mensagemTextarea.value.trim() !== '') {\n",
        "                    if (submitButton) {\n",
        "                        submitButton.disabled = true;\n",
        "                        submitButton.innerHTML = 'Analisando... <span class=\"animate-pulse\">⏳</span>';\n",
        "                    }\n",
        "                    if (loader) loader.style.display = 'block';\n",
        "                    if (resultadoBloco) resultadoBloco.style.display = 'none';\n",
        "                } else {\n",
        "                    // Impede o envio do formulário se a mensagem estiver vazia,\n",
        "                    // embora o 'required' no textarea já deva fazer isso.\n",
        "                    event.preventDefault();\n",
        "                }\n",
        "            });\n",
        "        }\n",
        "\n",
        "        // Garante que o bloco de resultado seja exibido se ele contiver conteúdo ao carregar a página.\n",
        "        // E esconde o loader se o resultado já estiver presente.\n",
        "        window.addEventListener('DOMContentLoaded', () => {\n",
        "            const resultadoBlocoPresente = document.getElementById('resultado-bloco');\n",
        "            const loaderElement = document.getElementById('loader');\n",
        "\n",
        "            // Verifica se o bloco de resultado existe E se ele tem conteúdo visível (não apenas espaços em branco)\n",
        "            // A verificação `offsetParent !== null` é uma forma de checar se o elemento está de fato visível no layout.\n",
        "            // No entanto, como estamos a definir `style=\"display: block;\"` no HTML se o Jinja o renderizar,\n",
        "            // podemos simplificar a verificação para apenas se o elemento existe.\n",
        "            if (resultadoBlocoPresente) {\n",
        "                resultadoBlocoPresente.style.display = 'block'; // Garante que está visível\n",
        "                if (loaderElement) loaderElement.style.display = 'none';\n",
        "\n",
        "                // Reabilita o botão se o resultado for exibido (após o recarregamento da página)\n",
        "                if (submitButton) {\n",
        "                    submitButton.disabled = false;\n",
        "                    submitButton.innerHTML = 'Analisar Mensagem';\n",
        "                }\n",
        "            }\n",
        "        });\n",
        "    </script>\n",
        "</body>\n",
        "</html>\n"
      ],
      "metadata": {
        "id": "STxgj9ChrIKw"
      },
      "id": "STxgj9ChrIKw",
      "execution_count": null,
      "outputs": []
    }
  ]
}